{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'radicalism_causes'\n",
    "train_percent = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key = {\n",
    "    'poverty_causes': \n",
    "    {\n",
    "        'file': 'data/poverty_causes.csv',\n",
    "        'text': 'Response', \n",
    "        'class': 'pcGEDO1', \n",
    "        'name': 'Causes of Poverty'\n",
    "    }, \n",
    "    'poverty_solutions':\n",
    "    {\n",
    "        'file': 'data/poverty_solutions.csv', \n",
    "        'text': 'Response', \n",
    "        'class': 'PSGEDO 1',\n",
    "        'name': 'Solutions to Poverty'\n",
    "        \n",
    "    },\n",
    "    'poverty_combined': \n",
    "    {\n",
    "        'file': None, \n",
    "        'text': 'Response', \n",
    "        'class': 'pcGEDO1', \n",
    "        'name': 'Causes and Solutions'\n",
    "    }, \n",
    "    'radicalism_solutions': \n",
    "    {\n",
    "        'file': 'data/radicalism_causes_solutions.csv', \n",
    "        'text': 'radsolution', \n",
    "        'class': 'GEDO 1.1',\n",
    "        'name': 'Solutions to Radicalism'\n",
    "    }, \n",
    "    'radicalism_causes': \n",
    "    {\n",
    "        'file': 'data/radicalism_causes_solutions.csv', \n",
    "        'text': 'radcause', \n",
    "        'class': 'GEDO 1',\n",
    "        'name': 'Causes of Radicalism'\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Setting up for', ds)\n",
    "if ds == 'poverty_combined': \n",
    "    df1 = pd.read_csv(data_key['poverty_solutions']['file'])\n",
    "    df2 = pd.read_csv(data_key['poverty_causes']['file'])\n",
    "    df1.rename(index=str, columns={'PSGEDO 1':'pcGEDO1'}, inplace=True)\n",
    "\n",
    "    c1 = df1[[data_key['poverty_solutions']['text'], data_key['poverty_causes']['class']]]\n",
    "    c2 = df2[[data_key['poverty_causes']['text'], data_key['poverty_causes']['class']]]\n",
    "    df = pd.concat([c1, c2])\n",
    "    print(df.head())\n",
    "else: \n",
    "    df = pd.read_csv(data_key[ds]['file'])\n",
    "    df.head()\n",
    "    df.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null\n",
    "df_not_null = df[df[data_key[ds]['text']].notnull()]\n",
    "df_not_null = df_not_null[df_not_null[data_key[ds]['class']].notnull()]\n",
    "\n",
    "df_not_null.shape\n",
    "\n",
    "# Remove categories that have fewer than 5 \n",
    "counts = df_not_null[data_key[ds]['class']].value_counts()\n",
    "remove = counts[counts < 5]\n",
    "for i, v in remove.items(): \n",
    "    print(i)\n",
    "    print(type(i))\n",
    "    df_not_null[data_key[ds]['class']] = df_not_null[data_key[ds]['class']][i != df_not_null[data_key[ds]['class']]]\n",
    "    \n",
    "df_not_null = df_not_null[df_not_null[data_key[ds]['class']].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_null[data_key[ds]['class']].value_counts().plot(kind='bar', title='Category counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "np.array(df_not_null[data_key[ds]['class']])\n",
    "le.fit(list(df_not_null[data_key[ds]['class']]))\n",
    "le.transform(list(df_not_null[data_key[ds]['class']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the testing and training data\n",
    "train = df_not_null.sample(frac=train_percent, random_state=42)\n",
    "test = df_not_null[~df_not_null.index.isin(train.index)]\n",
    "print('Number of values in training: ', train.shape[0], 'Number of values in testing: ', test.shape[0])\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "train[data_key[ds]['class']].value_counts().plot(kind='bar', title='Training Category Counts', ax=ax1)\n",
    "test[data_key[ds]['class']].value_counts().plot(kind='bar', title='Testing Category Counts', ax=ax2)\n",
    "print(type(test[data_key[ds]['class']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                        alpha=1e-3, random_state=42,\n",
    "                        max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_steps = [('vect', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()) ]\n",
    "\n",
    "clf_proc={}\n",
    "p = list(text_steps)\n",
    "p.append(('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                        alpha=1e-3, random_state=42, max_iter=100, tol=None)))\n",
    "ngram_list = [(1, 1), (1, 2), (1,3)]\n",
    "clf_proc['SGDClassifier'] = {\n",
    "    'pipeline': Pipeline(p), \n",
    "    'params': {\n",
    "              'vect__ngram_range': ngram_list,\n",
    "              'vect__analyzer': ['word', 'char'],\n",
    "              'vect__stop_words':['english'],\n",
    "              'clf__alpha': (1e-2, 1e-3, 1e-4, 1e-5),\n",
    "              'clf__loss':('log', 'hinge', 'modified_huber', 'perceptron', 'huber') \n",
    "              },\n",
    "            } \n",
    "p = list(text_steps)\n",
    "p.append(('clf', MultinomialNB()))\n",
    "\n",
    "clf_proc['NaiveBayes'] = {\n",
    "    'pipeline': Pipeline(p), \n",
    "    'params': {\n",
    "              'vect__ngram_range': ngram_list,\n",
    "              'vect__analyzer': ['word', 'char'],\n",
    "              'vect__stop_words':['english'],\n",
    "              'clf__alpha': (1e-2, 1e-3, 1e-4, 1e-5),\n",
    "              },\n",
    "            } \n",
    "\n",
    "p = list(text_steps)\n",
    "p.append(('clf', LinearSVC()))\n",
    "clf_proc['LinearSVC'] = {\n",
    "    'pipeline': Pipeline(p), \n",
    "    'params': {\n",
    "              'vect__ngram_range': ngram_list,\n",
    "              'vect__analyzer': ['word', 'char'],\n",
    "              'vect__stop_words':['english'],\n",
    "              'clf__loss':('hinge', 'squared_hinge'), \n",
    "              'clf__C': (1, 1e-2, 1e3, 1e-4)\n",
    "              },\n",
    "            } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "results = {}\n",
    "data_frames = {}\n",
    "for p in clf_proc: \n",
    "    print('Trying: ', p)\n",
    "    gs_clf = GridSearchCV(clf_proc[p]['pipeline'], clf_proc[p]['params'], n_jobs=-1)\n",
    "    gs_clf.fit(train[data_key[ds]['text']], list(train[data_key[ds]['class']]))  \n",
    "    print('best params:', gs_clf.best_params_)\n",
    "    print('best score:', gs_clf.best_score_)\n",
    "    predicted = gs_clf.predict(test[data_key[ds]['text']])\n",
    "    print('mean error: ', np.mean(predicted == test[data_key[ds]['class']]))\n",
    "    \n",
    "    print(metrics.classification_report(np.array(test[data_key[ds]['class']]), predicted))\n",
    "    results[p] = metrics.confusion_matrix(test[data_key[ds]['class']], predicted)\n",
    "    data_frames[p] = pd.DataFrame(data={'Text': test[data_key[ds]['text']], 'True Category': test[data_key[ds]['class']], 'Predicted Category': predicted})\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data_frames: \n",
    "    data_frames[d].to_csv(d+'_'+ds+'_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "keys = ['SGDClassifier', 'NaiveBayes', 'LinearSVC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "plt.figure()\n",
    "classes = sorted(set(test[data_key[ds]['class']]))\n",
    "plot_confusion_matrix(results[keys[idx]], classes=classes, title=keys[idx]+' Confusion Matrix of ' + data_key[ds]['name'], normalize=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "plt.figure()\n",
    "classes = sorted(set(test[data_key[ds]['class']]))\n",
    "plot_confusion_matrix(results[keys[idx]], classes=classes, title=keys[idx]+' Confusion Matrix of ' + data_key[ds]['name'], normalize=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "plt.figure()\n",
    "classes = sorted(set(test[data_key[ds]['class']]))\n",
    "plot_confusion_matrix(results[keys[idx]], classes=classes, title=keys[idx]+' Confusion Matrix of ' + data_key[ds]['name'], normalize=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of misclassification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_misclassified(idx, samples):\n",
    "    print('Errors for ', keys[idx])\n",
    "    f = data_frames[keys[idx]]\n",
    "    f = f[f['True Category'] != f['Predicted Category']]\n",
    "    unique = f['True Category'].unique()\n",
    "    for u in unique: \n",
    "        res = f[f['True Category'] == u]\n",
    "        count = 0\n",
    "        for i, row in res.iterrows(): \n",
    "            if count > (samples-1): \n",
    "                break\n",
    "            print ('Predicted:',row['Predicted Category'], 'Truth:', row['True Category'], 'Text: \\'', row['Text'],'\\'')\n",
    "            count +=1\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_misclassified(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_misclassified(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_misclassified(2, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
